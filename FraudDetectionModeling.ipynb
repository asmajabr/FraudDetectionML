{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FraudDetectionModeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbo5rIJh+taZ/6PodBC2wT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmajabr/FraudDetectionML/blob/master/FraudDetectionModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqSDA1khrDGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b7ba7dab-6545-401c-998c-4d1f18a3efbf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Vnp8D47nZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "43fb18fd-9044-4ddf-f998-deb97ddc8353"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print (cwd)\n",
        "!ls -lah"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 20K\n",
            "drwxr-xr-x 1 root root 4.0K Jul  1 05:21 .\n",
            "drwxr-xr-x 1 root root 4.0K Jul  1 05:16 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 .config\n",
            "drwx------ 4 root root 4.0K Jul  1 05:21 gdrive\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQvYBPig7v2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7cdb1e0a-f8bf-415b-a418-1a79ff4f8f6b"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "print (cwd)\n",
        "!ls -lah"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 20K\n",
            "drwxr-xr-x 1 root root 4.0K Jun 30 09:02 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 30 08:58 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 .config\n",
            "drwx------ 4 root root 4.0K Jun 30 09:02 gdrive\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMmx7WIq7z3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3848ba0e-e2e9-43fe-88b2-2bf31b72bfe2"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "print (cwd)\n",
        "!ls -lah"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 20K\n",
            "drwxr-xr-x 1 root root 4.0K Jun 30 09:02 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 30 08:58 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 .config\n",
            "drwx------ 4 root root 4.0K Jun 30 09:02 gdrive\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUIzqAAp70pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "ab6fd8dd-1521-4edf-ba2f-a4b433e8ef8b"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "url = \"/content/gdrive/My Drive/creditcard.csv\"\n",
        "\n",
        "creditcard = pd.read_csv(url)\n",
        "\n",
        "creditcard.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyJIcadN73ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-P2eD4q-V77",
        "colab_type": "text"
      },
      "source": [
        "Modeling Part 2: RandomForestClassifier\n",
        "1. Use the Imbalanced Data Directly in RandomForestClassifier\n",
        "2. Create Over-sampling data and Fit the model\n",
        "3. RandomForestClassifier with class_weight\n",
        "4. Self-defined Score and GridSearchCV of hyperparameter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmzmJRYs-YIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3FKKKUTCyig",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "As expected, use the imbalanced data is not a good way. The performance is the worst compared to using over-sampling or class weights\n",
        "Use imbalanced data, RandomForestClassifier result is better than LogisticRegression.\n",
        "If we can custom a good loss function, the model performance will be better: here the customed loss function performance is better than roc_auc scoring function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-QUVnTyCzL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer, scale\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import confusion_matrix, log_loss, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve\n",
        "from sklearn.metrics import make_scorer, precision_score, fbeta_score, f1_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "\n",
        "seed = 999\n",
        "\n",
        "\n",
        "creditcard.columns = [x.lower() for x in creditcard.columns]\n",
        "creditcard.rename(columns = {'class': 'fraud'}, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7fYWs3HDNDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "creditcard.drop(columns = 'time', inplace = True)\n",
        "\n",
        "# Normalize the 'amount' column\n",
        "scaler = StandardScaler()\n",
        "creditcard['amount'] = scaler.fit_transform(creditcard['amount'].values.reshape(-1, 1))\n",
        "# creditcard.drop(columns = 'amount', inplace = True)\n",
        "creditcard['amount']\n",
        "X = creditcard.iloc[:, :-1]\n",
        "y = creditcard.iloc[:, -1]\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRYwwofDDUOO",
        "colab_type": "text"
      },
      "source": [
        "For non-fraud transactions, the average amount is 88. For fraud transactions, the average amount is 122. So, in average there will be 122 loss for a fraud. Suppose for each transaction, the company can get 2% transaction fee. That is, the average is 88 * 2% = 1.76.\n",
        "\n",
        "That means: if we predict a non-fraud as fraud, we might loss 1.76. However, if we miss to detect a fraud transaction, we will loss about 122."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Sl2SHrDU9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg1YtphuDZrU",
        "colab_type": "text"
      },
      "source": [
        "Usually for imbalanced data, we can try:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfFZMfYDDaXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-yTNaFFDdfq",
        "colab_type": "text"
      },
      "source": [
        "1. Collect more data (which not work here since the data is given)\n",
        "2. Down-Sampling or Over-Sampling to get balanced samples\n",
        "3. Change the Thresholds to adjust the prediction\n",
        "4. Assign class weights for the low rate class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkTiQdzaDePH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szKRpr4GDhj1",
        "colab_type": "text"
      },
      "source": [
        "Here we will try 4 different ways and compare their results:\n",
        "\n",
        "2.1. Do nothing, use original data to model\n",
        "2.2. Do Over-Sampling, use the over-sampled data to model\n",
        "2.3. Assigning sample weights in RandomForestClassifier\n",
        "2.4. Use customed loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAtYoBXTDiSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTX-vzkQGwsE",
        "colab_type": "text"
      },
      "source": [
        "1. Use the Imbalanced Data Directly in RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wprsRctG12l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6f8b2e6f-8c68-4bf4-dbe9-08bd76720f3e"
      },
      "source": [
        "X = creditcard.iloc[:, :-1]\n",
        "y = creditcard.iloc[:, -1]\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)\n",
        "\n",
        "estimator = RandomForestClassifier(random_state=0, warm_start = True, n_jobs = 70)\n",
        "\n",
        "rf_tuned_parameters = {\"max_depth\": [10, 20, 50, 100], 'n_estimators': [50, 100, 200, 500], 'min_samples_leaf': [10, 20, 50]}\n",
        "\n",
        "cv_grid = GridSearchCV(estimator, param_grid = rf_tuned_parameters, scoring = 'roc_auc', verbose = 5) # 'recall', my_score\n",
        "cv_grid.fit(Xtrain, ytrain)\n",
        "\n",
        "# print cv_grid.cv_results_\n",
        "\n",
        "best_parameters = cv_grid.best_estimator_.get_params()\n",
        "\n",
        "# for param_name in sorted(rf_tuned_parameters.keys()):\n",
        "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "\n",
        "pred_test = cv_grid.predict(Xtest)\n",
        "print(recall_score(ytest, pred_test))     # 0.65\n",
        "print(precision_score(ytest, pred_test))  # 0.85\n",
        "print(roc_auc_score(ytest, pred_test))    # 0.83\n",
        "print(\"confustion matrix on validation data: \\n\" + str(confusion_matrix(ytest, pred_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV] max_depth=10, min_samples_leaf=10, n_estimators=50 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8zG6VGgqFn",
        "colab_type": "text"
      },
      "source": [
        "2. Create Over-sampling data and Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I78t9RTYgqz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "37a16177-c1cd-4d46-9451-5840d6023a55"
      },
      "source": [
        "oversample_ratio = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1\n",
        "# repeat the positive data for X and y\n",
        "ytrain_pos_oversample = pd.concat([ytrain[ytrain==1]] * oversample_ratio, axis = 0)\n",
        "Xtrain_pos_oversample = pd.concat([Xtrain.loc[ytrain==1, :]] * oversample_ratio, axis = 0)\n",
        "# concat the repeated data with the original data together\n",
        "ytrain_oversample = pd.concat([ytrain, ytrain_pos_oversample], axis = 0).reset_index(drop = True)\n",
        "Xtrain_oversample = pd.concat([Xtrain, Xtrain_pos_oversample], axis = 0).reset_index(drop = True)\n",
        "\n",
        "ytrain_oversample.value_counts(dropna = False, normalize = True)   # 50:50\n",
        "\n",
        "estimator = RandomForestClassifier(random_state=0, warm_start = True, n_jobs = 70)\n",
        "\n",
        "rf_tuned_parameters = {\"max_depth\": [10, 20, 50, 100], 'n_estimators': [50, 100, 200, 500], 'min_samples_leaf': [10, 20, 50]}\n",
        "\n",
        "cv_grid = GridSearchCV(estimator, param_grid = rf_tuned_parameters, scoring = 'roc_auc', verbose = 5) # 'recall', my_score\n",
        "cv_grid.fit(Xtrain_oversample, ytrain_oversample)\n",
        "\n",
        "# print cv_grid.best_params_\n",
        "# print cv_grid.cv_results_\n",
        "\n",
        "best_parameters = cv_grid.best_estimator_.get_params()\n",
        "\n",
        "# for param_name in sorted(rf_tuned_parameters.keys()):\n",
        "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "\n",
        "pred_test = cv_grid.predict(Xtest)\n",
        "print(recall_score(ytest, pred_test))     # 0.83\n",
        "print(precision_score(ytest, pred_test))  # 0.83\n",
        "print(roc_auc_score(ytest, pred_test))    # 0.92\n",
        "print(\"\\n confustion matrix on validation data: \\n\" + str(confusion_matrix(ytest, pred_test)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2cc9356f11d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moversample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# size to repeat y == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# repeat the positive data for X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mytrain_pos_oversample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moversample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mXtrain_pos_oversample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moversample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# concat the repeated data with the original data together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iQtkBhyhE0q",
        "colab_type": "text"
      },
      "source": [
        "3. RandomForestClassifier with class_weight\n",
        "\n",
        "---\n",
        "Rather than over-sampling, we can assign more weights to the lower rate class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4o6JRlhG1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ae2d9ed6-7429-4fb8-97fe-cef7e7e04a82"
      },
      "source": [
        "X = creditcard.iloc[:, :-1]\n",
        "y = creditcard.iloc[:, -1]\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)\n",
        "\n",
        "positive_weight = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1\n",
        "\n",
        "estimator = RandomForestClassifier(random_state=0, class_weight = {0 : 1, 1 : positive_weight}, warm_start = True, n_jobs = 70)\n",
        "\n",
        "rf_tuned_parameters = {\"max_depth\": [10, 20, 50, 100], 'n_estimators': [50, 100, 200, 500], 'min_samples_leaf': [10, 20, 50]}\n",
        "\n",
        "cv_grid = GridSearchCV(estimator, param_grid = rf_tuned_parameters, scoring = 'roc_auc', verbose = 5) # 'recall', my_score\n",
        "cv_grid.fit(Xtrain, ytrain)\n",
        "\n",
        "# print cv_grid.cv_results_\n",
        "\n",
        "best_parameters = cv_grid.best_estimator_.get_params()\n",
        "\n",
        "# for param_name in sorted(rf_tuned_parameters.keys()):\n",
        "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "\n",
        "pred_test = cv_grid.predict(Xtest)\n",
        "print(recall_score(ytest, pred_test))     #  0.85\n",
        "print(precision_score(ytest, pred_test))  #  0.81\n",
        "print(roc_auc_score(ytest, pred_test))    #  0.92\n",
        "print(\"\\n confustion matrix on validation data: \\n\" + str(confusion_matrix(ytest, pred_test)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70f3af9c4a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreditcard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreditcard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpositive_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# size to repeat y == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'creditcard' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Il5sbAhVOh",
        "colab_type": "text"
      },
      "source": [
        "4. Self-defined Score and GridSearchCV of hyperparameter:\n",
        "Since the loss from frauds and false predicted frauds are different for us. We will define a function to re-weight the effects by average loss from missing predicted frauds and falsely predicted frauds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYnCrcRzhV6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scoring(ground_truth, predictions):\n",
        "    '''\n",
        "    based on results above about the average loss from false positive and false negative predictions.\n",
        "    '''\n",
        "    cmatrix = confusion_matrix(ground_truth, predictions)\n",
        "    fp = cmatrix[0, 1]\n",
        "    fn = cmatrix[1, 0]\n",
        "    return  fn * 122 + fp * 1.76\n",
        "\n",
        "wt_loss_score = make_scorer(scoring, greater_is_better = False)\n",
        "\n",
        "oversample_ratio = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1\n",
        "# repeat the positive data for X and y\n",
        "ytrain_pos_oversample = pd.concat([ytrain[ytrain==1]] * oversample_ratio, axis = 0)\n",
        "Xtrain_pos_oversample = pd.concat([Xtrain.loc[ytrain==1, :]] * oversample_ratio, axis = 0)\n",
        "# concat the repeated data with the original data together\n",
        "ytrain_oversample = pd.concat([ytrain, ytrain_pos_oversample], axis = 0).reset_index(drop = True)\n",
        "Xtrain_oversample = pd.concat([Xtrain, Xtrain_pos_oversample], axis = 0).reset_index(drop = True)\n",
        "\n",
        "ytrain_oversample.value_counts(dropna = False, normalize = True)   # 50:50\n",
        "\n",
        "estimator = RandomForestClassifier(random_state=0, warm_start = True)\n",
        "\n",
        "rf_tuned_parameters = {\"max_depth\": [10, 20, 50, 100], 'n_estimators': [50, 100, 200, 500], \n",
        "                       'min_samples_leaf': [10, 20, 50]}\n",
        "\n",
        "cv_grid = GridSearchCV(estimator, param_grid = rf_tuned_parameters, scoring = wt_loss_score, verbose = 5, n_jobs = 70)\n",
        "cv_grid.fit(Xtrain_oversample, ytrain_oversample)\n",
        "\n",
        "# print cv_grid.best_params_\n",
        "\n",
        "pred_test = cv_grid.predict(Xtest)\n",
        "print(recall_score(ytest, pred_test))     # 0.84\n",
        "print(precision_score(ytest, pred_test))  # 0.84\n",
        "print(roc_auc_score(ytest, pred_test))    # 0.92\n",
        "print(\"\\n confustion matrix on validation data: \\n\" + str(confusion_matrix(ytest, pred_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaAKnZOEhn1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}